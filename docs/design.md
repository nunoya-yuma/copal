# パーソナルリサーチエージェント：プロジェクト設計書

## プロジェクト名
Copal - Co（一緒に）+ Pal（友達）= いつも一緒にいる相棒。琥珀の前段階の樹脂という意味もある。

## プロジェクト概要
LLMを活用したローカル処理優先の個人向け調査・情報整理アシスタント。複数の情報源からデータを収集・統合し、ユーザーの文脈に合わせた深い洞察を提供する。Rustで実装し、高性能・プライバシー保護・カスタマイズ性を重視する。

## 機能概要

### 1. 情報収集と統合
- **マルチソース検索**: Web、ローカルファイル、PDF、個人ノートから同時に関連情報を収集
- **継続的モニタリング**: 指定トピックの新情報自動通知
- **データインポート**: 既存ノート・ブックマーク取り込み

### 2. インテリジェント処理
- **コンテキスト対応要約**: ユーザーの知識レベル・関心に合わせた要約生成
- **関連性分析**: 新情報と過去調査の関連性分析、知識の穴を特定
- **事実確認**: 複数ソースからの情報比較で信頼性評価

### 3. インタラクティブな調査支援
- **会話型調査**: 自然な会話での調査深掘り
- **調査シナリオ**: 調査パターンのテンプレート化・再利用
- **思考整理**: 調査中のアイデア記録・関連情報自動リンク

### 4. プラクティカルな出力
- **カスタム形式**: レポート、メモ、プレゼン資料など様々な形式で出力
- **引用トレース**: 全情報源の正確な記録・引用
- **アクションアイテム抽出**: 調査結果から次のアクションを自動抽出

## 技術アーキテクチャ

```
┌─────────────────────────────────────────────────────────────────┐
│                      ユーザーインターフェース                          │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐   ┌──────────────┐   │
│  │   CLI    │  │   GUI    │  │   API    │   │ ブラウザ拡張    │   │
│  └────┬─────┘  └────┬─────┘  └────┬─────┘   └──────┬───────┘   │
└───────┼──────────────┼──────────────┼──────────────┼────────────┘
        │              │              │              │
┌───────▼──────────────▼──────────────▼──────────────▼────────────┐
│                         コアエンジン                             │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐  │
│  │ クエリ解析         │  │ 調査計画生成     │  │ レスポンス合成     │  │
│  └────────┬────────┘  └────────┬────────┘  └────────┬────────┘  │
│           │                    │                    │           │
│  ┌────────▼────────────────────▼────────────────────▼────────┐  │
│  │                      オーケストレーター                         │  │
│  └────────┬────────────────────┬────────────────────┬────────┘  │
└───────────┼────────────────────┼────────────────────┼───────────┘
            │                    │                    │
┌───────────▼────────┐  ┌────────▼───────┐  ┌────────▼───────────┐
│   情報収集モジュール │  │  LLMコネクタ   │  │   ストレージモジュール │
│ ┌─────────────────┐│  │┌─────────────┐ │  │ ┌─────────────────┐ │
│ │  ウェブスクレイパー││  ││ OpenAI     │ │  │ │ベクトルDB管理   │ │
│ └─────────────────┘│  │└─────────────┘ │  │ └─────────────────┘ │
│ ┌─────────────────┐│  │┌─────────────┐ │  │ ┌─────────────────┐ │
│ │  PDFプロセッサ   ││  ││ Gemini     │ │  │ │メタデータストア  │ │
│ └─────────────────┘│  │└─────────────┘ │  │ └─────────────────┘ │
│ ┌─────────────────┐│  │┌─────────────┐ │  │ ┌─────────────────┐ │
│ │ローカルファイル  ││  ││ ローカルモデル│ │  │ │  履歴管理     │ │
│ └─────────────────┘│  │└─────────────┘ │  │ └─────────────────┘ │
└────────────────────┘  └────────────────┘  └─────────────────────┘
```

## コンポーネント詳細

### 1. ユーザーインターフェース層
- **CLI**: Rust製の高速なコマンドラインツール（`clap`等利用）
- **GUI**: Tauriフレームワークを使用したデスクトップアプリ（後期フェーズ）

### 2. コアエンジン
- **クエリ解析**: ユーザー入力を解析し意図を理解
- **調査計画生成**: 複数のデータソースへのクエリを最適化
- **レスポンス合成**: 複数ソースからの情報を統合
- **オーケストレーター**: 全モジュール間の通信と処理フローを制御

### 3. 情報収集モジュール
- **ウェブスクレイパー**: 並列処理でウェブ情報を効率的に収集
- **PDFプロセッサ**: PDF文書からテキスト・構造を抽出
- **ローカルファイル**: ファイルシステムから関連文書を検索・解析

### 4. LLMコネクタ
- **マルチバックエンド**: OpenAI、Gemini、ローカルモデルに対応
- **プロンプト管理**: 効果的なプロンプトテンプレートの管理
- **コンテキスト最適化**: トークン制限内で関連情報を最大化

### 5. ストレージモジュール
- **ベクトルDB**: セマンティック検索のための埋め込みストレージ（Qdrant等）
- **メタデータストア**: ドキュメント属性、タグ、関連情報の管理
- **履歴管理**: ユーザーの調査履歴と進行状況の保存

## 技術スタック（Rustクレート）

### コア（実装済み）
- **tokio**: 非同期ランタイム
- **reqwest**: HTTPクライアント（ウェブ情報取得）
- **scraper**: HTMLパース
- **serde** + **serde_json**: シリアライゼーション
- **clap**: コマンドラインインターフェース
- **rustyline**: REPL入力
- **anyhow** + **thiserror**: エラー処理
- **log** + **env_logger**: ログ

### LLMインテグレーション（実装済み）
- **rig-core**: マルチプロバイダー対応LLMフレームワーク（Ollama / OpenAI / Gemini）

### 情報処理（予定）
- **lopdf** / **pdf**: PDF処理
- **tantivy**: 全文検索エンジン
- **qdrant-client**: ローカルベクトルデータベース

### UI（段階的に実装）
- **crossterm** / **tui**: ターミナルUI（初期段階）
- **tauri**: デスクトップGUI（後期段階）

## 開発フェーズ

### フェーズ1: 基盤実装 ✅
- ✅ プロジェクト構造セットアップ
- ✅ CLIインターフェース基本実装
- ✅ シンプルなウェブスクレイピング
- ✅ LLMインテグレーション（マルチプロバイダー: Ollama / OpenAI / Gemini）
- ✅ インタラクティブモード（REPL）
- ✅ 会話履歴管理

### フェーズ2: コア機能実装
- 複数情報源からのデータ取得
- ベクトルDBでの保存と検索
- プロンプトテンプレート実装
- 基本的な会話コンテキスト

### フェーズ3: 高度機能実装
- PDFや他の文書形式の処理
- メタデータと関連性分析
- 調査計画の最適化
- 並列処理とパフォーマンス改善

### フェーズ4: UI改善とテスト
- リッチCLIまたは簡易GUIの実装
- エラーハンドリングとロギング強化
- ユーザーテスト
- パッケージング

## LLMモデル選定
- OpenAI API
- Gemini API
- Ollama（ローカルモデル: Llama、Mixtral、Phi-3など）

## 実装方針
- 完全ローカル実装を優先
- プライバシー保護を重視
- Rust学習を兼ねた実装
